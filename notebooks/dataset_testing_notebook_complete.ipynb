{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Mask Detection Dataset Testing Notebook\n",
    "\n",
    "This notebook is completely self-contained and includes all the necessary code to load and test the face mask detection datasets using PyTorch Dataset classes with Kaggle integration.\n",
    "\n",
    "## Features:\n",
    "- PyTorch Dataset classes with proper `__getitem__` and `__len__` methods\n",
    "- Kaggle API integration for automatic dataset downloading\n",
    "- Intelligent caching system\n",
    "- Support for both detection and classification tasks\n",
    "- Data transforms and augmentation\n",
    "- Train/validation/test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Setup\n",
    "\n",
    "First, install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision kagglehub Pillow tqdm pandas matplotlib opencv-python lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Union, Any, Callable\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import kagglehub\n",
    "import cv2\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Dataset Manager\n",
    "\n",
    "This class handles downloading and managing datasets from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KaggleDatasetManager:\n",
    "    \"\"\"Manages downloading and caching of Kaggle datasets.\"\"\"\n",
    "    \n",
    "    DATASETS = {\n",
    "        'andrewmvd': {\n",
    "            'name': 'andrewmvd/face-mask-detection',\n",
    "            'description': 'Face Mask Detection dataset with bounding box annotations',\n",
    "            'type': 'detection',\n",
    "            'classes': ['with_mask', 'without_mask', 'mask_weared_incorrect']\n",
    "        },\n",
    "        'face12k': {\n",
    "            'name': 'ashishjangra27/face-mask-12k-images-dataset',\n",
    "            'description': '12K Face Mask Images Dataset for classification',\n",
    "            'type': 'classification',\n",
    "            'classes': ['With Mask', 'Without Mask']\n",
    "        },\n",
    "        'medical_mask': {\n",
    "            'name': 'vtech6/medical-masks-dataset',\n",
    "            'description': 'Medical Masks Dataset',\n",
    "            'type': 'classification',\n",
    "            'classes': ['mask', 'no_mask']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def __init__(self, cache_dir: Optional[str] = None):\n",
    "        if cache_dir is None:\n",
    "            cache_dir = os.path.join(tempfile.gettempdir(), 'kaggle_datasets')\n",
    "        \n",
    "        self.cache_dir = Path(cache_dir)\n",
    "        self.cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.metadata_file = self.cache_dir / 'dataset_metadata.json'\n",
    "        self.metadata = self._load_metadata()\n",
    "    \n",
    "    def _load_metadata(self) -> Dict:\n",
    "        if self.metadata_file.exists():\n",
    "            try:\n",
    "                with open(self.metadata_file, 'r') as f:\n",
    "                    return json.load(f)\n",
    "            except (json.JSONDecodeError, IOError):\n",
    "                pass\n",
    "        return {}\n",
    "    \n",
    "    def _save_metadata(self):\n",
    "        try:\n",
    "            with open(self.metadata_file, 'w') as f:\n",
    "                json.dump(self.metadata, f, indent=2)\n",
    "        except IOError as e:\n",
    "            print(f\"Warning: Could not save metadata: {e}\")\n",
    "    \n",
    "    def download_dataset(self, dataset_key: str, force_redownload: bool = False) -> Path:\n",
    "        if dataset_key not in self.DATASETS:\n",
    "            raise ValueError(f\"Unknown dataset: {dataset_key}. Available: {list(self.DATASETS.keys())}\")\n",
    "        \n",
    "        dataset_info = self.DATASETS[dataset_key]\n",
    "        dataset_name = dataset_info['name']\n",
    "        \n",
    "        dataset_dir = self.cache_dir / dataset_key\n",
    "        if not force_redownload and self._is_dataset_valid(dataset_key):\n",
    "            print(f\"Dataset '{dataset_key}' already downloaded and valid at: {dataset_dir}\")\n",
    "            return dataset_dir\n",
    "        \n",
    "        print(f\"Downloading dataset '{dataset_key}' from Kaggle...\")\n",
    "        print(f\"Dataset: {dataset_name}\")\n",
    "        print(f\"Description: {dataset_info['description']}\")\n",
    "        \n",
    "        try:\n",
    "            download_path = kagglehub.dataset_download(dataset_name)\n",
    "            download_path = Path(download_path)\n",
    "            \n",
    "            if dataset_dir.exists():\n",
    "                shutil.rmtree(dataset_dir)\n",
    "            \n",
    "            shutil.move(str(download_path), str(dataset_dir))\n",
    "            \n",
    "            self.metadata[dataset_key] = {\n",
    "                'name': dataset_name,\n",
    "                'download_time': time.time(),\n",
    "                'path': str(dataset_dir),\n",
    "                'info': dataset_info\n",
    "            }\n",
    "            self._save_metadata()\n",
    "            \n",
    "            print(f\"Successfully downloaded '{dataset_key}' to: {dataset_dir}\")\n",
    "            return dataset_dir\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to download dataset '{dataset_key}': {str(e)}\")\n",
    "    \n",
    "    def _is_dataset_valid(self, dataset_key: str) -> bool:\n",
    "        if dataset_key not in self.metadata:\n",
    "            return False\n",
    "        \n",
    "        dataset_dir = Path(self.metadata[dataset_key]['path'])\n",
    "        return dataset_dir.exists() and any(dataset_dir.iterdir())\n",
    "    \n",
    "    def list_available_datasets(self) -> Dict[str, Dict]:\n",
    "        return self.DATASETS.copy()\n",
    "    \n",
    "    def get_dataset_info(self, dataset_key: str) -> Dict:\n",
    "        if dataset_key not in self.DATASETS:\n",
    "            raise ValueError(f\"Unknown dataset: {dataset_key}\")\n",
    "        return self.DATASETS[dataset_key].copy()\n",
    "\n",
    "print(\"KaggleDatasetManager class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Classes\n",
    "\n",
    "These classes handle data transforms for both detection and classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTransforms:\n",
    "    \"\"\"Transforms for image classification tasks.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 image_size: Tuple[int, int] = (224, 224),\n",
    "                 augment: bool = True,\n",
    "                 normalize: bool = True):\n",
    "        transform_list = []\n",
    "        \n",
    "        # Resize\n",
    "        transform_list.append(transforms.Resize(image_size))\n",
    "        \n",
    "        # Augmentation\n",
    "        if augment:\n",
    "            transform_list.extend([\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "                transforms.RandomRotation(10),\n",
    "            ])\n",
    "        \n",
    "        # Convert to tensor\n",
    "        transform_list.append(transforms.ToTensor())\n",
    "        \n",
    "        # Normalize\n",
    "        if normalize:\n",
    "            transform_list.append(\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            )\n",
    "        \n",
    "        self.transform = transforms.Compose(transform_list)\n",
    "    \n",
    "    def __call__(self, image: Image.Image) -> torch.Tensor:\n",
    "        return self.transform(image)\n",
    "\n",
    "\n",
    "class DetectionTransforms:\n",
    "    \"\"\"Transforms for object detection tasks (images + bounding boxes).\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 image_size: Tuple[int, int] = (416, 416),\n",
    "                 augment: bool = True,\n",
    "                 normalize: bool = True):\n",
    "        self.image_size = image_size\n",
    "        self.augment = augment\n",
    "        self.normalize = normalize\n",
    "    \n",
    "    def __call__(self, image: Image.Image, bboxes: List[Dict]) -> Tuple[torch.Tensor, List[Dict]]:\n",
    "        # Resize image\n",
    "        image = F.resize(image, self.image_size)\n",
    "        \n",
    "        # Apply augmentations\n",
    "        flip_horizontal = False\n",
    "        if self.augment:\n",
    "            # Color jitter\n",
    "            if random.random() < 0.5:\n",
    "                color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
    "                image = color_jitter(image)\n",
    "            \n",
    "            # Horizontal flip\n",
    "            if random.random() < 0.5:\n",
    "                image = F.hflip(image)\n",
    "                flip_horizontal = True\n",
    "        \n",
    "        # Convert to tensor and normalize\n",
    "        image = F.to_tensor(image)\n",
    "        if self.normalize:\n",
    "            image = F.normalize(image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        # Transform bounding boxes\n",
    "        transformed_bboxes = []\n",
    "        for bbox_info in bboxes:\n",
    "            bbox = bbox_info['bbox'].copy() if isinstance(bbox_info['bbox'], list) else list(bbox_info['bbox'])\n",
    "            \n",
    "            # Handle horizontal flip\n",
    "            if flip_horizontal:\n",
    "                x_min, y_min, x_max, y_max = bbox\n",
    "                bbox = [1.0 - x_max, y_min, 1.0 - x_min, y_max]\n",
    "            \n",
    "            transformed_bbox = {\n",
    "                'bbox': bbox,\n",
    "                'class': bbox_info['class']\n",
    "            }\n",
    "            \n",
    "            # Copy any additional fields\n",
    "            for key, value in bbox_info.items():\n",
    "                if key not in ['bbox', 'class']:\n",
    "                    transformed_bbox[key] = value\n",
    "            \n",
    "            transformed_bboxes.append(transformed_bbox)\n",
    "        \n",
    "        return image, transformed_bboxes\n",
    "\n",
    "print(\"Transform classes defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Dataset Classes\n",
    "\n",
    "These are the main PyTorch Dataset classes that implement the `__getitem__` and `__len__` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AndrewMVDPyTorchDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for AndrewMVD Face Mask Detection dataset.\n",
    "    \n",
    "    Supports both detection and classification modes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 dataset_path: Union[str, Path],\n",
    "                 mode: str = 'detection',\n",
    "                 split: str = 'train',\n",
    "                 transform: Optional[Callable] = None,\n",
    "                 split_ratios: Tuple[float, float, float] = (0.7, 0.15, 0.15)):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset_path: Path to the dataset directory\n",
    "            mode: 'detection' or 'classification'\n",
    "            split: 'train', 'val', or 'test'\n",
    "            transform: Transform to apply to images\n",
    "            split_ratios: (train, val, test) ratios\n",
    "        \"\"\"\n",
    "        self.dataset_path = Path(dataset_path)\n",
    "        self.mode = mode\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Class mappings\n",
    "        self.class_names = ['with_mask', 'without_mask', 'mask_weared_incorrect']\n",
    "        self.class_to_idx = {name: idx for idx, name in enumerate(self.class_names)}\n",
    "        \n",
    "        # Load data\n",
    "        self.samples = self._load_samples()\n",
    "        \n",
    "        # Split data\n",
    "        self.samples = self._split_data(self.samples, split_ratios)\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} samples for {split} split in {mode} mode\")\n",
    "    \n",
    "    def _load_samples(self) -> List[Dict]:\n",
    "        \"\"\"Load all samples from the dataset.\"\"\"\n",
    "        samples = []\n",
    "        \n",
    "        images_dir = self.dataset_path / 'images'\n",
    "        annotations_dir = self.dataset_path / 'annotations'\n",
    "        \n",
    "        if not images_dir.exists() or not annotations_dir.exists():\n",
    "            raise FileNotFoundError(f\"Images or annotations directory not found in {self.dataset_path}\")\n",
    "        \n",
    "        # Process each XML annotation file\n",
    "        for xml_file in annotations_dir.glob('*.xml'):\n",
    "            image_file = images_dir / f\"{xml_file.stem}.png\"\n",
    "            \n",
    "            if not image_file.exists():\n",
    "                continue\n",
    "            \n",
    "            # Parse XML annotation\n",
    "            try:\n",
    "                tree = ET.parse(xml_file)\n",
    "                root = tree.getroot()\n",
    "                \n",
    "                # Get image dimensions\n",
    "                size = root.find('size')\n",
    "                img_width = int(size.find('width').text)\n",
    "                img_height = int(size.find('height').text)\n",
    "                \n",
    "                # Extract bounding boxes\n",
    "                bboxes = []\n",
    "                for obj in root.findall('object'):\n",
    "                    class_name = obj.find('name').text\n",
    "                    \n",
    "                    bbox = obj.find('bndbox')\n",
    "                    x_min = int(bbox.find('xmin').text)\n",
    "                    y_min = int(bbox.find('ymin').text)\n",
    "                    x_max = int(bbox.find('xmax').text)\n",
    "                    y_max = int(bbox.find('ymax').text)\n",
    "                    \n",
    "                    # Normalize coordinates\n",
    "                    x_min_norm = x_min / img_width\n",
    "                    y_min_norm = y_min / img_height\n",
    "                    x_max_norm = x_max / img_width\n",
    "                    y_max_norm = y_max / img_height\n",
    "                    \n",
    "                    bboxes.append({\n",
    "                        'bbox': [x_min_norm, y_min_norm, x_max_norm, y_max_norm],\n",
    "                        'class': class_name,\n",
    "                        'class_idx': self.class_to_idx.get(class_name, 0)\n",
    "                    })\n",
    "                \n",
    "                if bboxes:  # Only add if there are annotations\n",
    "                    samples.append({\n",
    "                        'image_path': str(image_file),\n",
    "                        'bboxes': bboxes,\n",
    "                        'image_id': xml_file.stem\n",
    "                    })\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Failed to parse {xml_file}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def _split_data(self, samples: List[Dict], split_ratios: Tuple[float, float, float]) -> List[Dict]:\n",
    "        \"\"\"Split data into train/val/test sets.\"\"\"\n",
    "        random.shuffle(samples)\n",
    "        \n",
    "        train_ratio, val_ratio, test_ratio = split_ratios\n",
    "        total_samples = len(samples)\n",
    "        \n",
    "        train_end = int(total_samples * train_ratio)\n",
    "        val_end = int(total_samples * (train_ratio + val_ratio))\n",
    "        \n",
    "        if self.split == 'train':\n",
    "            return samples[:train_end]\n",
    "        elif self.split == 'val':\n",
    "            return samples[train_end:val_end]\n",
    "        else:  # test\n",
    "            return samples[val_end:]\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(sample['image_path']).convert('RGB')\n",
    "        \n",
    "        if self.mode == 'detection':\n",
    "            # Detection mode: return image and bounding boxes\n",
    "            bboxes = sample['bboxes']\n",
    "            \n",
    "            if self.transform:\n",
    "                image, bboxes = self.transform(image, bboxes)\n",
    "            \n",
    "            return {\n",
    "                'image': image,\n",
    "                'bboxes': bboxes,\n",
    "                'image_id': sample['image_id']\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            # Classification mode: return image and dominant class\n",
    "            # Use the most common class in the image\n",
    "            class_counts = defaultdict(int)\n",
    "            for bbox in sample['bboxes']:\n",
    "                class_counts[bbox['class_idx']] += 1\n",
    "            \n",
    "            dominant_class = max(class_counts.items(), key=lambda x: x[1])[0]\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return {\n",
    "                'image': image,\n",
    "                'label': dominant_class,\n",
    "                'image_id': sample['image_id']\n",
    "            }\n",
    "\n",
    "\n",
    "class Face12kPyTorchDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for Face12k classification dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 dataset_path: Union[str, Path],\n",
    "                 split: str = 'train',\n",
    "                 transform: Optional[Callable] = None,\n",
    "                 split_ratios: Tuple[float, float, float] = (0.7, 0.15, 0.15)):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset_path: Path to the dataset directory\n",
    "            split: 'train', 'val', or 'test'\n",
    "            transform: Transform to apply to images\n",
    "            split_ratios: (train, val, test) ratios\n",
    "        \"\"\"\n",
    "        self.dataset_path = Path(dataset_path)\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Class mappings\n",
    "        self.class_names = ['With Mask', 'Without Mask']\n",
    "        self.class_to_idx = {name: idx for idx, name in enumerate(self.class_names)}\n",
    "        \n",
    "        # Load data\n",
    "        self.samples = self._load_samples()\n",
    "        \n",
    "        # Split data\n",
    "        self.samples = self._split_data(self.samples, split_ratios)\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} samples for {split} split\")\n",
    "    \n",
    "    def _load_samples(self) -> List[Dict]:\n",
    "        \"\"\"Load all samples from the dataset.\"\"\"\n",
    "        samples = []\n",
    "        \n",
    "        for class_name in self.class_names:\n",
    "            class_dir = self.dataset_path / class_name\n",
    "            \n",
    "            if not class_dir.exists():\n",
    "                print(f\"Warning: Class directory {class_dir} not found\")\n",
    "                continue\n",
    "            \n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "            \n",
    "            # Load all images in the class directory\n",
    "            for img_file in class_dir.glob('*'):\n",
    "                if img_file.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
    "                    samples.append({\n",
    "                        'image_path': str(img_file),\n",
    "                        'label': class_idx,\n",
    "                        'class_name': class_name,\n",
    "                        'image_id': img_file.stem\n",
    "                    })\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def _split_data(self, samples: List[Dict], split_ratios: Tuple[float, float, float]) -> List[Dict]:\n",
    "        \"\"\"Split data into train/val/test sets.\"\"\"\n",
    "        # Stratified split by class\n",
    "        class_samples = defaultdict(list)\n",
    "        for sample in samples:\n",
    "            class_samples[sample['label']].append(sample)\n",
    "        \n",
    "        split_samples = []\n",
    "        train_ratio, val_ratio, test_ratio = split_ratios\n",
    "        \n",
    "        for class_idx, class_data in class_samples.items():\n",
    "            random.shuffle(class_data)\n",
    "            \n",
    "            total_samples = len(class_data)\n",
    "            train_end = int(total_samples * train_ratio)\n",
    "            val_end = int(total_samples * (train_ratio + val_ratio))\n",
    "            \n",
    "            if self.split == 'train':\n",
    "                split_samples.extend(class_data[:train_end])\n",
    "            elif self.split == 'val':\n",
    "                split_samples.extend(class_data[train_end:val_end])\n",
    "            else:  # test\n",
    "                split_samples.extend(class_data[val_end:])\n",
    "        \n",
    "        random.shuffle(split_samples)\n",
    "        return split_samples\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(sample['image_path']).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'label': sample['label'],\n",
    "            'image_id': sample['image_id']\n",
    "        }\n",
    "\n",
    "print(\"PyTorch Dataset classes defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Factory\n",
    "\n",
    "Factory class for easy dataset creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFactory:\n",
    "    \"\"\"Factory for creating datasets with appropriate transforms.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_dataset(dataset_name: str, \n",
    "                      dataset_path: Union[str, Path],\n",
    "                      mode: str = 'classification',\n",
    "                      split: str = 'train',\n",
